# DiffusionPipeline ç±»æ–¹æ³•è¯¦ç»†è¯´æ˜

## ç›®å½•
- [ç±»å±æ€§](#ç±»å±æ€§)
- [æ ¸å¿ƒæ–¹æ³•](#æ ¸å¿ƒæ–¹æ³•)
- [è®¾å¤‡å’Œå†…å­˜ç®¡ç†](#è®¾å¤‡å’Œå†…å­˜ç®¡ç†)
- [æ³¨æ„åŠ›ä¼˜åŒ–](#æ³¨æ„åŠ›ä¼˜åŒ–)
- [VAEä¼˜åŒ–](#vaeä¼˜åŒ–)
- [å·¥å…·æ–¹æ³•](#å·¥å…·æ–¹æ³•)
- [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)

## ç±»å±æ€§

### åŸºç¡€å±æ€§
| å±æ€§å | ç±»å‹ | é»˜è®¤å€¼ | åŸå§‹æè¿° | ä¸­æ–‡è¯´æ˜ |
|--------|------|--------|----------|----------|
| `config_name` | `str` | `"model_index.json"` | The configuration filename that stores the class and module names of all the diffusion pipeline's components. | å­˜å‚¨æ‰©æ•£Pipelineæ‰€æœ‰ç»„ä»¶çš„ç±»åå’Œæ¨¡å—åçš„é…ç½®æ–‡ä»¶å |
| `model_cpu_offload_seq` | `Optional[str]` | `None` | - | æ¨¡å‹CPUå¸è½½åºåˆ—ï¼Œå®šä¹‰æ¨¡å‹å¸è½½é¡ºåº |
| `hf_device_map` | `Optional[Dict]` | `None` | - | HuggingFaceè®¾å¤‡æ˜ å°„é…ç½® |
| `_optional_components` | `List[str]` | `[]` | List of all optional components that don't have to be passed to the pipeline to function (should be overridden by subclasses). | æ‰€æœ‰å¯é€‰ç»„ä»¶çš„åˆ—è¡¨ï¼Œè¿™äº›ç»„ä»¶ä¸å¿…ä¼ é€’ç»™Pipelineå³å¯è¿è¡Œï¼ˆåº”ç”±å­ç±»é‡å†™ï¼‰ |
| `_exclude_from_cpu_offload` | `List[str]` | `[]` | - | ä»CPUå¸è½½ä¸­æ’é™¤çš„ç»„ä»¶åˆ—è¡¨ |
| `_load_connected_pipes` | `bool` | `False` | - | æ˜¯å¦åŠ è½½è¿æ¥çš„Pipeline |
| `_is_onnx` | `bool` | `False` | - | æ˜¯å¦ä¸ºONNX Pipeline |

## æ ¸å¿ƒæ–¹æ³•

### 1. `__init__` æ–¹æ³•
```python
def __init__(self, *args, **kwargs)
```
**æè¿°**: Pipelineçš„åˆå§‹åŒ–æ–¹æ³•ï¼Œç”±å­ç±»å®ç°å…·ä½“çš„ç»„ä»¶åˆå§‹åŒ–ã€‚

**å‚æ•°**:
- `*args`: ä½ç½®å‚æ•°ï¼Œé€šå¸¸åŒ…å«Pipelineçš„å„ä¸ªç»„ä»¶
- `**kwargs`: å…³é”®å­—å‚æ•°ï¼Œç”¨äºä¼ é€’é¢å¤–é…ç½®

---

### 2. `register_modules` æ–¹æ³•
```python
def register_modules(self, **kwargs)
```
**æè¿°**: æ³¨å†ŒPipelineçš„æ¨¡å—ç»„ä»¶ï¼Œå°†ç»„ä»¶ä¿¡æ¯ä¿å­˜åˆ°é…ç½®ä¸­ã€‚

**å‚æ•°**:
- `**kwargs`: è¦æ³¨å†Œçš„æ¨¡å—ï¼Œé”®ä¸ºæ¨¡å—åï¼Œå€¼ä¸ºæ¨¡å—å¯¹è±¡

**åŠŸèƒ½**:
- è‡ªåŠ¨æ£€æµ‹æ¨¡å—çš„åº“å’Œç±»å
- å°†æ¨¡å—ä¿¡æ¯æ³¨å†Œåˆ°é…ç½®ä¸­
- è®¾ç½®æ¨¡å—ä¸ºPipelineçš„å±æ€§

**ç¤ºä¾‹**:
```python
pipeline.register_modules(
    unet=unet_model,
    vae=vae_model,
    scheduler=scheduler
)
```

---

### 3. `save_pretrained` æ–¹æ³•
```python
def save_pretrained(
    self,
    save_directory: Union[str, os.PathLike],
    safe_serialization: bool = True,
    variant: Optional[str] = None,
    max_shard_size: Optional[Union[int, str]] = None,
    push_to_hub: bool = False,
    **kwargs
)
```
**åŸå§‹æ–‡æ¡£**: Save all saveable variables of the pipeline to a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading method. The pipeline is easily reloaded using the [`~DiffusionPipeline.from_pretrained`] class method.

**ä¸­æ–‡æè¿°**: å°†Pipelineçš„æ‰€æœ‰å¯ä¿å­˜å˜é‡ä¿å­˜åˆ°ç›®å½•ä¸­ã€‚å¦‚æœPipelineå˜é‡çš„ç±»å®ç°äº†ä¿å­˜å’ŒåŠ è½½æ–¹æ³•ï¼Œåˆ™å¯ä»¥ä¿å­˜å’ŒåŠ è½½è¯¥å˜é‡ã€‚å¯ä»¥ä½¿ç”¨[`~DiffusionPipeline.from_pretrained`]ç±»æ–¹æ³•è½»æ¾é‡æ–°åŠ è½½Pipelineã€‚

**å‚æ•°è¯¦è§£**:
- `save_directory` (`str` or `os.PathLike`): Directory to save a pipeline to. Will be created if it doesn't exist. | ä¿å­˜Pipelineçš„ç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨å°†è¢«åˆ›å»º
- `safe_serialization` (`bool`, *optional*, defaults to `True`): Whether to save the model using `safetensors` or the traditional PyTorch way with `pickle`. | æ˜¯å¦ä½¿ç”¨`safetensors`ä¿å­˜æ¨¡å‹ï¼Œæˆ–ä½¿ç”¨ä¼ ç»Ÿçš„PyTorchæ–¹å¼ä¸`pickle`
- `variant` (`str`, *optional*): If specified, weights are saved in the format `pytorch_model.<variant>.bin`. | å¦‚æœæŒ‡å®šï¼Œæƒé‡å°†ä»¥`pytorch_model.<variant>.bin`æ ¼å¼ä¿å­˜
- `max_shard_size` (`int` or `str`, defaults to `None`): The maximum size for a checkpoint before being sharded. | åˆ†ç‰‡å‰æ£€æŸ¥ç‚¹çš„æœ€å¤§å¤§å°
- `push_to_hub` (`bool`, *optional*, defaults to `False`): Whether or not to push your model to the Hugging Face model hub after saving it. | ä¿å­˜åæ˜¯å¦å°†æ¨¡å‹æ¨é€åˆ°Hugging Faceæ¨¡å‹ä¸­å¿ƒ
- `**kwargs` (`Dict[str, Any]`, *optional*): Additional keyword arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method. | ä¼ é€’ç»™[`~utils.PushToHubMixin.push_to_hub`]æ–¹æ³•çš„é¢å¤–å…³é”®å­—å‚æ•°

**ç¤ºä¾‹**:
```python
# åŸºç¡€ä¿å­˜
pipeline.save_pretrained("./my_pipeline")

# ä¿å­˜fp16å˜ä½“å¹¶æ¨é€åˆ°Hub
pipeline.save_pretrained(
    "./my_pipeline",
    variant="fp16",
    push_to_hub=True,
    repo_id="my_username/my_pipeline"
)
```

---

### 4. `from_pretrained` ç±»æ–¹æ³•
```python
@classmethod
def from_pretrained(
    cls, 
    pretrained_model_name_or_path: Optional[Union[str, os.PathLike]], 
    **kwargs
) -> Self
```
**æè¿°**: ä»é¢„è®­ç»ƒæƒé‡å®ä¾‹åŒ–PyTorchæ‰©æ•£Pipelineã€‚

**æ ¸å¿ƒå‚æ•°**:
- `pretrained_model_name_or_path` (`str` | `os.PathLike`): 
  - Hubä»“åº“ID (å¦‚ `"CompVis/ldm-text2im-large-256"`)
  - æœ¬åœ°ç›®å½•è·¯å¾„ (å¦‚ `"./my_pipeline_directory/"`)
  - DDUFæ–‡ä»¶è·¯å¾„

**æ•°æ®ç±»å‹å‚æ•°**:
- `torch_dtype` (`torch.dtype` | `dict`): 
  - å•ä¸€ç±»å‹: `torch.float16`
  - ç»„ä»¶ç‰¹å®š: `{'transformer': torch.bfloat16, 'vae': torch.float16}`
  - å¸¦é»˜è®¤å€¼: `{'transformer': torch.bfloat16, 'default': torch.float16}`

**è‡ªå®šä¹‰Pipelineå‚æ•°**:
- `custom_pipeline` (`str`): 
  - Hubä»“åº“ID: `"hf-internal-testing/diffusers-dummy-pipeline"`
  - ç¤¾åŒºPipelineå: `"clip_guided_stable_diffusion"`
  - æœ¬åœ°ç›®å½•: `"./my_pipeline_directory/"`

**ä¸‹è½½æ§åˆ¶å‚æ•°**:
- `force_download` (`bool`, é»˜è®¤ `False`): å¼ºåˆ¶é‡æ–°ä¸‹è½½
- `cache_dir` (`str`): ç¼“å­˜ç›®å½•è·¯å¾„
- `local_files_only` (`bool`, é»˜è®¤ `False`): ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
- `token` (`str` | `bool`): HuggingFaceè®¿é—®ä»¤ç‰Œ
- `revision` (`str`, é»˜è®¤ `"main"`): æ¨¡å‹ç‰ˆæœ¬åˆ†æ”¯/æ ‡ç­¾/æäº¤ID
- `custom_revision` (`str`): è‡ªå®šä¹‰Pipelineçš„ç‰ˆæœ¬

**ç½‘ç»œå‚æ•°**:
- `proxies` (`Dict[str, str]`): ä»£ç†æœåŠ¡å™¨é…ç½®
- `mirror` (`str`): é•œåƒæºåœ°å€ï¼ˆä¸­å›½ç”¨æˆ·ï¼‰

**è®¾å¤‡æ˜ å°„å‚æ•°**:
- `device_map` (`str`): è®¾å¤‡æ˜ å°„ç­–ç•¥ï¼Œç›®å‰æ”¯æŒ"balanced"
- `max_memory` (`Dict`): æ¯ä¸ªè®¾å¤‡çš„æœ€å¤§å†…å­˜é™åˆ¶
- `offload_folder` (`str`): ç£ç›˜å¸è½½ç›®å½•
- `offload_state_dict` (`bool`): æ˜¯å¦ä¸´æ—¶å¸è½½CPUçŠ¶æ€å­—å…¸

**å†…å­˜ä¼˜åŒ–å‚æ•°**:
- `low_cpu_mem_usage` (`bool`): ä½CPUå†…å­˜ä½¿ç”¨æ¨¡å¼
- `use_safetensors` (`bool`): æ˜¯å¦ä½¿ç”¨safetensorsæ ¼å¼
- `use_onnx` (`bool`): æ˜¯å¦ä½¿ç”¨ONNXæƒé‡
- `variant` (`str`): æƒé‡å˜ä½“ï¼Œå¦‚"fp16"
- `dduf_file` (`str`): DDUFæ–‡ä»¶è·¯å¾„

**å…¶ä»–å‚æ•°**:
- `output_loading_info` (`bool`, é»˜è®¤ `False`): è¿”å›åŠ è½½ä¿¡æ¯
- `quantization_config`: é‡åŒ–é…ç½®
- `**kwargs`: è¦†ç›–Pipelineç»„ä»¶çš„å‚æ•°

**ç¤ºä¾‹**:
```python
# åŸºç¡€åŠ è½½
pipeline = DiffusionPipeline.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5")

# æŒ‡å®šæ•°æ®ç±»å‹å’Œè®¾å¤‡
pipeline = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    torch_dtype=torch.float16,
    device_map="balanced",
    use_safetensors=True
)

# ç»„ä»¶ç‰¹å®šæ•°æ®ç±»å‹
pipeline = DiffusionPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-schnell",
    torch_dtype={
        'transformer': torch.bfloat16,
        'vae': torch.float16,
        'default': torch.float32
    }
)

# ä½¿ç”¨è‡ªå®šä¹‰è°ƒåº¦å™¨
from diffusers import LMSDiscreteScheduler
pipeline = DiffusionPipeline.from_pretrained(
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    scheduler=LMSDiscreteScheduler.from_config(scheduler_config)
)
```

---

### 5. `to` æ–¹æ³•
```python
def to(self, *args, **kwargs) -> Self
```
**æè¿°**: æ‰§è¡ŒPipelineçš„æ•°æ®ç±»å‹å’Œ/æˆ–è®¾å¤‡è½¬æ¢ã€‚

**è°ƒç”¨æ–¹å¼**:
- `to(dtype)`: è½¬æ¢åˆ°æŒ‡å®šæ•°æ®ç±»å‹
- `to(device)`: è½¬æ¢åˆ°æŒ‡å®šè®¾å¤‡
- `to(device, dtype)`: åŒæ—¶è½¬æ¢è®¾å¤‡å’Œæ•°æ®ç±»å‹
- `to(device=None, dtype=None, silence_dtype_warnings=False)`: å…³é”®å­—å‚æ•°æ–¹å¼

**å‚æ•°**:
- `dtype` (`torch.dtype`, å¯é€‰): ç›®æ ‡æ•°æ®ç±»å‹
- `device` (`torch.device`, å¯é€‰): ç›®æ ‡è®¾å¤‡
- `silence_dtype_warnings` (`bool`, é»˜è®¤ `False`): æ˜¯å¦é™é»˜æ•°æ®ç±»å‹è­¦å‘Š

**è¿”å›å€¼**: è½¬æ¢åçš„Pipelineå®ä¾‹ï¼ˆå¦‚æœå·²ç»æ˜¯ç›®æ ‡ç±»å‹åˆ™è¿”å›è‡ªèº«ï¼‰

**ç¤ºä¾‹**:
```python
# ç§»åŠ¨åˆ°GPU
pipeline = pipeline.to("cuda")

# è½¬æ¢æ•°æ®ç±»å‹
pipeline = pipeline.to(torch.float16)

# åŒæ—¶è½¬æ¢è®¾å¤‡å’Œæ•°æ®ç±»å‹
pipeline = pipeline.to("cuda", torch.float16)

# é™é»˜è­¦å‘Š
pipeline = pipeline.to("cuda", silence_dtype_warnings=True)
```

---

### 6. `download` ç±»æ–¹æ³•
```python
@classmethod
def download(cls, pretrained_model_name, **kwargs) -> Union[str, os.PathLike]
```
**æè¿°**: ä¸‹è½½å¹¶ç¼“å­˜PyTorchæ‰©æ•£Pipelineï¼Œä½†ä¸å®ä¾‹åŒ–ã€‚

**å‚æ•°**:
- `pretrained_model_name` (`str`): Hubä»“åº“ID
- `custom_pipeline` (`str`, å¯é€‰): è‡ªå®šä¹‰Pipeline
- `force_download` (`bool`, é»˜è®¤ `False`): å¼ºåˆ¶é‡æ–°ä¸‹è½½
- `proxies` (`Dict[str, str]`, å¯é€‰): ä»£ç†é…ç½®
- `output_loading_info` (`bool`, é»˜è®¤ `False`): è¿”å›åŠ è½½ä¿¡æ¯
- `local_files_only` (`bool`, é»˜è®¤ `False`): ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
- `token` (`str` | `bool`, å¯é€‰): è®¿é—®ä»¤ç‰Œ
- `revision` (`str`, é»˜è®¤ `"main"`): ç‰ˆæœ¬

**è¿”å›å€¼**: ä¸‹è½½çš„æ¨¡å‹è·¯å¾„

**ç¤ºä¾‹**:
```python
# ä¸‹è½½æ¨¡å‹åˆ°ç¼“å­˜
model_path = DiffusionPipeline.download("stable-diffusion-v1-5/stable-diffusion-v1-5")
print(f"æ¨¡å‹ä¸‹è½½åˆ°: {model_path}")
```

## å±æ€§è®¿é—®å™¨

### 7. `device` å±æ€§
```python
@property
def device(self) -> torch.device
```
**æè¿°**: è¿”å›Pipelineæ‰€åœ¨çš„torchè®¾å¤‡ã€‚

**è¿”å›å€¼**: Pipelineå½“å‰æ‰€åœ¨çš„è®¾å¤‡

**ç¤ºä¾‹**:
```python
print(f"Pipelineåœ¨è®¾å¤‡: {pipeline.device}")
# è¾“å‡º: Pipelineåœ¨è®¾å¤‡: cuda:0
```

---

### 8. `dtype` å±æ€§
```python
@property
def dtype(self) -> torch.dtype
```
**æè¿°**: è¿”å›Pipelineçš„torchæ•°æ®ç±»å‹ã€‚

**è¿”å›å€¼**: Pipelineçš„æ•°æ®ç±»å‹

**ç¤ºä¾‹**:
```python
print(f"Pipelineæ•°æ®ç±»å‹: {pipeline.dtype}")
# è¾“å‡º: Pipelineæ•°æ®ç±»å‹: torch.float16
```

---

### 9. `components` å±æ€§
```python
@property
def components(self) -> Dict[str, Any]
```
**æè¿°**: è¿”å›Pipelineçš„æ‰€æœ‰ç»„ä»¶å­—å…¸ï¼Œç”¨äºåœ¨ä¸åŒPipelineé—´å…±äº«æƒé‡å’Œé…ç½®ã€‚

**è¿”å›å€¼**: åŒ…å«æ‰€æœ‰Pipelineç»„ä»¶çš„å­—å…¸

**ç¤ºä¾‹**:
```python
components = pipeline.components
print("Pipelineç»„ä»¶:", list(components.keys()))
# è¾“å‡º: Pipelineç»„ä»¶: ['vae', 'text_encoder', 'tokenizer', 'unet', 'scheduler']

# ä½¿ç”¨ç»„ä»¶åˆ›å»ºæ–°Pipeline
new_pipeline = AnotherPipeline(**components)
```

---

### 10. `name_or_path` å±æ€§
```python
@property
def name_or_path(self) -> str
```
**æè¿°**: è¿”å›Pipelineçš„åç§°æˆ–è·¯å¾„ã€‚

**è¿”å›å€¼**: Pipelineçš„åŸå§‹åç§°æˆ–è·¯å¾„

## è®¾å¤‡å’Œå†…å­˜ç®¡ç†

### 11. `enable_model_cpu_offload` æ–¹æ³•
```python
def enable_model_cpu_offload(self, gpu_id: Optional[int] = None, device: Union[torch.device, str] = None)
```
**æè¿°**: ä½¿ç”¨accelerateå°†æ‰€æœ‰æ¨¡å‹å¸è½½åˆ°CPUï¼Œä»¥è¾ƒä½çš„æ€§èƒ½å½±å“å‡å°‘å†…å­˜ä½¿ç”¨ã€‚ä¸`enable_sequential_cpu_offload`ç›¸æ¯”ï¼Œæ­¤æ–¹æ³•åœ¨è°ƒç”¨`forward`æ–¹æ³•æ—¶å°†æ•´ä¸ªæ¨¡å‹ç§»åŠ¨åˆ°åŠ é€Ÿå™¨ï¼Œæ¨¡å‹ä¿æŒåœ¨åŠ é€Ÿå™¨ä¸Šç›´åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹è¿è¡Œã€‚

**å‚æ•°**:
- `gpu_id` (`int`, å¯é€‰): æ¨ç†æ—¶ä½¿ç”¨çš„åŠ é€Ÿå™¨IDï¼Œé»˜è®¤ä¸º0
- `device` (`torch.device` | `str`, å¯é€‰): æ¨ç†æ—¶ä½¿ç”¨çš„PyTorchè®¾å¤‡ç±»å‹ï¼Œè‡ªåŠ¨æ£€æµ‹å¯ç”¨åŠ é€Ÿå™¨

**ç‰¹ç‚¹**:
- å†…å­˜èŠ‚çœä½äº`enable_sequential_cpu_offload`
- æ€§èƒ½å½±å“è¾ƒå°ï¼Œå› ä¸ºUNetçš„è¿­ä»£æ‰§è¡Œ
- é€‚åˆéœ€è¦å¹³è¡¡å†…å­˜å’Œæ€§èƒ½çš„åœºæ™¯

**ç¤ºä¾‹**:
```python
# ä½¿ç”¨é»˜è®¤GPU
pipeline.enable_model_cpu_offload()

# æŒ‡å®šGPU ID
pipeline.enable_model_cpu_offload(gpu_id=1)

# æŒ‡å®šè®¾å¤‡
pipeline.enable_model_cpu_offload(device="cuda:1")
```

---

### 12. `enable_sequential_cpu_offload` æ–¹æ³•
```python
def enable_sequential_cpu_offload(self, gpu_id: Optional[int] = None, device: Union[torch.device, str] = None)
```
**æè¿°**: ä½¿ç”¨ğŸ¤— Accelerateå°†æ‰€æœ‰æ¨¡å‹å¸è½½åˆ°CPUï¼Œæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ã€‚æ‰€æœ‰`torch.nn.Module`ç»„ä»¶çš„çŠ¶æ€å­—å…¸ä¿å­˜åˆ°CPUï¼Œç„¶åç§»åŠ¨åˆ°`torch.device('meta')`ï¼Œä»…åœ¨ç‰¹å®šå­æ¨¡å—è°ƒç”¨`forward`æ–¹æ³•æ—¶åŠ è½½åˆ°åŠ é€Ÿå™¨ã€‚

**å‚æ•°**:
- `gpu_id` (`int`, å¯é€‰): æ¨ç†æ—¶ä½¿ç”¨çš„åŠ é€Ÿå™¨IDï¼Œé»˜è®¤ä¸º0
- `device` (`torch.device` | `str`, å¯é€‰): æ¨ç†æ—¶ä½¿ç”¨çš„PyTorchè®¾å¤‡ç±»å‹

**ç‰¹ç‚¹**:
- å†…å­˜èŠ‚çœé«˜äº`enable_model_cpu_offload`
- æ€§èƒ½å½±å“è¾ƒå¤§ï¼Œå› ä¸ºå­æ¨¡å—çº§åˆ«çš„å¸è½½
- é€‚åˆå†…å­˜æåº¦å—é™çš„åœºæ™¯

**ç¤ºä¾‹**:
```python
# å¯ç”¨é¡ºåºCPUå¸è½½
pipeline.enable_sequential_cpu_offload()

# æŒ‡å®šè®¾å¤‡
pipeline.enable_sequential_cpu_offload(device="cuda:0")
```

---

### 13. `remove_all_hooks` æ–¹æ³•
```python
def remove_all_hooks(self)
```
**æè¿°**: ç§»é™¤ä½¿ç”¨`enable_sequential_cpu_offload`æˆ–`enable_model_cpu_offload`æ—¶æ·»åŠ çš„æ‰€æœ‰é’©å­ã€‚

**åŠŸèƒ½**:
- æ¸…ç†æ‰€æœ‰accelerateé’©å­
- æ¢å¤æ¨¡å‹åˆ°æ­£å¸¸çŠ¶æ€
- é‡Šæ”¾é’©å­å ç”¨çš„èµ„æº

**ç¤ºä¾‹**:
```python
# ç§»é™¤æ‰€æœ‰å¸è½½é’©å­
pipeline.remove_all_hooks()
```

---

### 14. `maybe_free_model_hooks` æ–¹æ³•
```python
def maybe_free_model_hooks(self)
```
**æè¿°**: æ‰§è¡Œä»¥ä¸‹æ“ä½œçš„æ–¹æ³•ï¼š
- å¸è½½æ‰€æœ‰ç»„ä»¶
- ç§»é™¤ä½¿ç”¨`enable_model_cpu_offload`æ—¶æ·»åŠ çš„æ‰€æœ‰æ¨¡å‹é’©å­ï¼Œç„¶åé‡æ–°åº”ç”¨
- é‡ç½®å»å™ªå™¨ç»„ä»¶çš„æœ‰çŠ¶æ€æ‰©æ•£é’©å­

**ç”¨é€”**: åœ¨Pipelineçš„`__call__`å‡½æ•°æœ«å°¾æ·»åŠ æ­¤å‡½æ•°ï¼Œç¡®ä¿åœ¨åº”ç”¨`enable_model_cpu_offload`æ—¶æ­£å¸¸å·¥ä½œã€‚

**ç¤ºä¾‹**:
```python
# é€šå¸¸åœ¨Pipelineå†…éƒ¨è°ƒç”¨
def __call__(self, *args, **kwargs):
    # ... Pipelineé€»è¾‘ ...
    self.maybe_free_model_hooks()
    return result
```

---

### 15. `reset_device_map` æ–¹æ³•
```python
def reset_device_map(self)
```
**æè¿°**: å°†è®¾å¤‡æ˜ å°„ï¼ˆå¦‚æœæœ‰ï¼‰é‡ç½®ä¸ºNoneã€‚

**åŠŸèƒ½**:
- ç§»é™¤æ‰€æœ‰é’©å­
- å°†æ‰€æœ‰ç»„ä»¶ç§»åŠ¨åˆ°CPU
- æ¸…ç©ºè®¾å¤‡æ˜ å°„é…ç½®

**ç¤ºä¾‹**:
```python
# é‡ç½®è®¾å¤‡æ˜ å°„
pipeline.reset_device_map()
```

## æ³¨æ„åŠ›ä¼˜åŒ–

### 16. `enable_xformers_memory_efficient_attention` æ–¹æ³•
```python
def enable_xformers_memory_efficient_attention(self, attention_op: Optional[Callable] = None)
```
**æè¿°**: å¯ç”¨æ¥è‡ªxFormersçš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œåº”è¯¥è§‚å¯Ÿåˆ°æ›´ä½çš„GPUå†…å­˜ä½¿ç”¨å’Œæ¨ç†æœŸé—´çš„æ½œåœ¨åŠ é€Ÿã€‚

**å‚æ•°**:
- `attention_op` (`Callable`, å¯é€‰): è¦†ç›–é»˜è®¤çš„`None`æ“ä½œç¬¦ï¼Œç”¨ä½œxFormersçš„`memory_efficient_attention()`å‡½æ•°çš„`op`å‚æ•°

**æ³¨æ„äº‹é¡¹**:
- âš ï¸ å½“å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›éƒ½å¯ç”¨æ—¶ï¼Œå†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ä¼˜å…ˆ
- è®­ç»ƒæœŸé—´çš„åŠ é€Ÿä¸ä¿è¯

**ç¤ºä¾‹**:
```python
# å¯ç”¨xFormerså†…å­˜é«˜æ•ˆæ³¨æ„åŠ›
pipeline.enable_xformers_memory_efficient_attention()

# ä½¿ç”¨ç‰¹å®šæ“ä½œç¬¦
from xformers.ops import MemoryEfficientAttentionFlashAttentionOp
pipeline.enable_xformers_memory_efficient_attention(
    attention_op=MemoryEfficientAttentionFlashAttentionOp
)

# VAEçš„Flash Attentionå˜é€šæ–¹æ¡ˆ
pipeline.vae.enable_xformers_memory_efficient_attention(attention_op=None)
```

---

### 17. `disable_xformers_memory_efficient_attention` æ–¹æ³•
```python
def disable_xformers_memory_efficient_attention(self)
```
**æè¿°**: ç¦ç”¨æ¥è‡ªxFormersçš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚

**ç¤ºä¾‹**:
```python
# ç¦ç”¨xFormerså†…å­˜é«˜æ•ˆæ³¨æ„åŠ›
pipeline.disable_xformers_memory_efficient_attention()
```

---

### 18. `enable_attention_slicing` æ–¹æ³•
```python
def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = "auto")
```
**æè¿°**: å¯ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ³¨æ„åŠ›æ¨¡å—å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆåˆ‡ç‰‡ï¼Œåˆ†å‡ ä¸ªæ­¥éª¤è®¡ç®—æ³¨æ„åŠ›ã€‚å¯¹äºå¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œè®¡ç®—åœ¨æ¯ä¸ªå¤´ä¸Šé¡ºåºæ‰§è¡Œã€‚

**å‚æ•°**:
- `slice_size` (`str` | `int`, é»˜è®¤ `"auto"`):
  - `"auto"`: å°†æ³¨æ„åŠ›å¤´çš„è¾“å…¥å‡åŠï¼Œæ³¨æ„åŠ›å°†åˆ†ä¸¤æ­¥è®¡ç®—
  - `"max"`: é€šè¿‡ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªåˆ‡ç‰‡æ¥èŠ‚çœæœ€å¤§å†…å­˜
  - æ•°å­—: ä½¿ç”¨`attention_head_dim // slice_size`ä¸ªåˆ‡ç‰‡ï¼Œ`attention_head_dim`å¿…é¡»æ˜¯`slice_size`çš„å€æ•°

**æ³¨æ„äº‹é¡¹**:
- âš ï¸ å¦‚æœå·²ç»ä½¿ç”¨PyTorch 2.0çš„`scaled_dot_product_attention`(SDPA)æˆ–xFormersï¼Œä¸è¦å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡
- è¿™äº›æ³¨æ„åŠ›è®¡ç®—å·²ç»éå¸¸å†…å­˜é«˜æ•ˆï¼Œå¯ç”¨åˆ‡ç‰‡å¯èƒ½å¯¼è‡´ä¸¥é‡å‡é€Ÿ

**ç¤ºä¾‹**:
```python
# è‡ªåŠ¨åˆ‡ç‰‡
pipeline.enable_attention_slicing()

# æœ€å¤§å†…å­˜èŠ‚çœ
pipeline.enable_attention_slicing("max")

# è‡ªå®šä¹‰åˆ‡ç‰‡å¤§å°
pipeline.enable_attention_slicing(4)
```

---

### 19. `disable_attention_slicing` æ–¹æ³•
```python
def disable_attention_slicing(self)
```
**æè¿°**: ç¦ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å¦‚æœä¹‹å‰è°ƒç”¨äº†`enable_attention_slicing`ï¼Œæ³¨æ„åŠ›å°†åœ¨ä¸€æ­¥ä¸­è®¡ç®—ã€‚

**ç¤ºä¾‹**:
```python
# ç¦ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡
pipeline.disable_attention_slicing()
```

---

### 20. `set_attention_slice` æ–¹æ³•
```python
def set_attention_slice(self, slice_size: Optional[int])
```
**æè¿°**: è®¾ç½®æ³¨æ„åŠ›åˆ‡ç‰‡å¤§å°çš„å†…éƒ¨æ–¹æ³•ã€‚

**å‚æ•°**:
- `slice_size` (`int`, å¯é€‰): åˆ‡ç‰‡å¤§å°ï¼Œ`None`è¡¨ç¤ºç¦ç”¨åˆ‡ç‰‡

**åŠŸèƒ½**: éå†æ‰€æœ‰æ”¯æŒæ³¨æ„åŠ›åˆ‡ç‰‡çš„æ¨¡å—å¹¶è®¾ç½®åˆ‡ç‰‡å¤§å°

## VAEä¼˜åŒ–

### 21. `enable_vae_slicing` æ–¹æ³•
```python
def enable_vae_slicing(self)
```
**æè¿°**: å¯ç”¨åˆ‡ç‰‡VAEè§£ç ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†è¾“å…¥å¼ é‡åˆ†å‰²æˆåˆ‡ç‰‡ï¼Œåˆ†å‡ ä¸ªæ­¥éª¤è®¡ç®—è§£ç ã€‚è¿™å¯¹èŠ‚çœå†…å­˜å’Œå…è®¸æ›´å¤§çš„æ‰¹æ¬¡å¤§å°å¾ˆæœ‰ç”¨ã€‚

**ç‰¹ç‚¹**:
- å†…å­˜èŠ‚çœï¼šä¸­ç­‰
- æ€§èƒ½å½±å“ï¼šå¾ˆå°
- é€‚ç”¨åœºæ™¯ï¼šéœ€è¦å¤„ç†å¤§æ‰¹æ¬¡æˆ–é«˜åˆ†è¾¨ç‡å›¾åƒ

**ç¤ºä¾‹**:
```python
# å¯ç”¨VAEåˆ‡ç‰‡
pipeline.enable_vae_slicing()
```

---

### 22. `disable_vae_slicing` æ–¹æ³•
```python
def disable_vae_slicing(self)
```
**æè¿°**: ç¦ç”¨åˆ‡ç‰‡VAEè§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº†`enable_vae_slicing`ï¼Œæ­¤æ–¹æ³•å°†å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚

**ç¤ºä¾‹**:
```python
# ç¦ç”¨VAEåˆ‡ç‰‡
pipeline.disable_vae_slicing()
```

---

### 23. `enable_vae_tiling` æ–¹æ³•
```python
def enable_vae_tiling(self)
```
**æè¿°**: å¯ç”¨å¹³é“ºVAEè§£ç ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAEå°†è¾“å…¥å¼ é‡åˆ†å‰²æˆç“¦ç‰‡ï¼Œåˆ†å‡ ä¸ªæ­¥éª¤è®¡ç®—è§£ç å’Œç¼–ç ã€‚è¿™å¯¹èŠ‚çœå¤§é‡å†…å­˜å’Œå…è®¸å¤„ç†æ›´å¤§å›¾åƒéå¸¸æœ‰ç”¨ã€‚

**ç‰¹ç‚¹**:
- å†…å­˜èŠ‚çœï¼šé«˜
- æ€§èƒ½å½±å“ï¼šè½»å¾®
- é€‚ç”¨åœºæ™¯ï¼šå¤„ç†è¶…é«˜åˆ†è¾¨ç‡å›¾åƒæˆ–å†…å­˜ä¸¥é‡å—é™

**ç¤ºä¾‹**:
```python
# å¯ç”¨VAEå¹³é“º
pipeline.enable_vae_tiling()
```

---

### 24. `disable_vae_tiling` æ–¹æ³•
```python
def disable_vae_tiling(self)
```
**æè¿°**: ç¦ç”¨å¹³é“ºVAEè§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº†`enable_vae_tiling`ï¼Œæ­¤æ–¹æ³•å°†å›åˆ°ä¸€æ­¥è®¡ç®—è§£ç ã€‚

**ç¤ºä¾‹**:
```python
# ç¦ç”¨VAEå¹³é“º
pipeline.disable_vae_tiling()
```

## å·¥å…·æ–¹æ³•

### 25. `progress_bar` æ–¹æ³•
```python
def progress_bar(self, iterable=None, total=None)
```
**æè¿°**: åˆ›å»ºè¿›åº¦æ¡ç”¨äºæ˜¾ç¤ºæ¨ç†è¿›åº¦ã€‚

**å‚æ•°**:
- `iterable` (å¯é€‰): å¯è¿­ä»£å¯¹è±¡ï¼Œç”¨äºåŒ…è£…è¿›åº¦æ¡
- `total` (å¯é€‰): æ€»æ­¥æ•°ï¼Œç”¨äºåˆ›å»ºæ‰‹åŠ¨æ›´æ–°çš„è¿›åº¦æ¡

**è¿”å›å€¼**: tqdmè¿›åº¦æ¡å¯¹è±¡

**æ³¨æ„**: `iterable`å’Œ`total`å¿…é¡»æä¾›å…¶ä¸­ä¸€ä¸ª

**ç¤ºä¾‹**:
```python
# åŒ…è£…å¯è¿­ä»£å¯¹è±¡
for step in pipeline.progress_bar(range(50)):
    # æ‰§è¡Œæ¨ç†æ­¥éª¤
    pass

# æ‰‹åŠ¨è¿›åº¦æ¡
pbar = pipeline.progress_bar(total=50)
for i in range(50):
    # æ‰§è¡Œæ“ä½œ
    pbar.update(1)
```

---

### 26. `set_progress_bar_config` æ–¹æ³•
```python
def set_progress_bar_config(self, **kwargs)
```
**æè¿°**: è®¾ç½®è¿›åº¦æ¡é…ç½®å‚æ•°ã€‚

**å‚æ•°**:
- `**kwargs`: tqdmè¿›åº¦æ¡çš„é…ç½®å‚æ•°

**å¸¸ç”¨é…ç½®**:
- `disable` (`bool`): æ˜¯å¦ç¦ç”¨è¿›åº¦æ¡
- `desc` (`str`): è¿›åº¦æ¡æè¿°
- `leave` (`bool`): å®Œæˆåæ˜¯å¦ä¿ç•™è¿›åº¦æ¡
- `position` (`int`): è¿›åº¦æ¡ä½ç½®

**ç¤ºä¾‹**:
```python
# ç¦ç”¨è¿›åº¦æ¡
pipeline.set_progress_bar_config(disable=True)

# è‡ªå®šä¹‰è¿›åº¦æ¡
pipeline.set_progress_bar_config(
    desc="ç”Ÿæˆå›¾åƒ",
    leave=False,
    position=0
)
```

---

### 27. `numpy_to_pil` é™æ€æ–¹æ³•
```python
@staticmethod
def numpy_to_pil(images)
```
**æè¿°**: å°†NumPyå›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡è½¬æ¢ä¸ºPILå›¾åƒã€‚

**å‚æ•°**:
- `images`: NumPyæ•°ç»„æ ¼å¼çš„å›¾åƒ

**è¿”å›å€¼**: PILå›¾åƒåˆ—è¡¨

**ç¤ºä¾‹**:
```python
import numpy as np

# è½¬æ¢NumPyå›¾åƒä¸ºPIL
numpy_images = np.random.rand(2, 512, 512, 3)
pil_images = DiffusionPipeline.numpy_to_pil(numpy_images)
```

---

### 28. `from_pipe` ç±»æ–¹æ³•
```python
@classmethod
def from_pipe(cls, pipeline, **kwargs)
```
**æè¿°**: ä»ç»™å®šPipelineåˆ›å»ºæ–°Pipelineã€‚æ­¤æ–¹æ³•å¯¹äºä»ç°æœ‰Pipelineç»„ä»¶åˆ›å»ºæ–°Pipelineè€Œä¸é‡æ–°åˆ†é…é¢å¤–å†…å­˜å¾ˆæœ‰ç”¨ã€‚

**å‚æ•°**:
- `pipeline` (`DiffusionPipeline`): æºPipeline
- `**kwargs`: è¦†ç›–ç»„ä»¶æˆ–é…ç½®çš„å‚æ•°

**è¿”å›å€¼**: å…·æœ‰ç›¸åŒæƒé‡å’Œé…ç½®çš„æ–°Pipeline

**ç‰¹ç‚¹**:
- é‡ç”¨ç°æœ‰ç»„ä»¶ï¼ŒèŠ‚çœå†…å­˜
- å¯ä»¥è¦†ç›–ç‰¹å®šç»„ä»¶
- ä¿æŒåŸå§‹é…ç½®

**ç¤ºä¾‹**:
```python
from diffusers import StableDiffusionPipeline, StableDiffusionSAGPipeline

# åˆ›å»ºåŸºç¡€Pipeline
base_pipe = StableDiffusionPipeline.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5")

# ä»åŸºç¡€Pipelineåˆ›å»ºSAG Pipeline
sag_pipe = StableDiffusionSAGPipeline.from_pipe(base_pipe)

# è¦†ç›–ç‰¹å®šç»„ä»¶
new_pipe = StableDiffusionPipeline.from_pipe(
    base_pipe,
    scheduler=new_scheduler,
    torch_dtype=torch.float16
)
```

## é«˜çº§åŠŸèƒ½

### 29. `enable_freeu` æ–¹æ³•
```python
def enable_freeu(self, s1: float, s2: float, b1: float, b2: float)
```
**æè¿°**: å¯ç”¨FreeUæœºåˆ¶ï¼Œå¦‚è®ºæ–‡https://huggingface.co/papers/2309.11497æ‰€è¿°ã€‚ç¼©æ”¾å› å­åçš„åç¼€è¡¨ç¤ºåº”ç”¨çš„é˜¶æ®µã€‚

**å‚æ•°**:
- `s1` (`float`): é˜¶æ®µ1çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è·ƒç‰¹å¾çš„è´¡çŒ®ï¼Œç¼“è§£å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„"è¿‡åº¦å¹³æ»‘æ•ˆåº”"
- `s2` (`float`): é˜¶æ®µ2çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è·ƒç‰¹å¾çš„è´¡çŒ®
- `b1` (`float`): é˜¶æ®µ1çš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®
- `b2` (`float`): é˜¶æ®µ2çš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®

**é€‚ç”¨æ¨¡å‹**: éœ€è¦Pipelineå…·æœ‰`unet`ç»„ä»¶

**æ¨èå€¼**: è¯·å‚è€ƒå®˜æ–¹ä»“åº“è·å–é€‚ç”¨äºä¸åŒPipelineçš„å·²çŸ¥æœ‰æ•ˆå€¼ç»„åˆ

**ç¤ºä¾‹**:
```python
# Stable Diffusion v1.5æ¨èå€¼
pipeline.enable_freeu(s1=0.9, s2=0.2, b1=1.2, b2=1.4)

# Stable Diffusion XLæ¨èå€¼
pipeline.enable_freeu(s1=0.6, s2=0.4, b1=1.1, b2=1.2)
```

---

### 30. `disable_freeu` æ–¹æ³•
```python
def disable_freeu(self)
```
**æè¿°**: å¦‚æœå¯ç”¨äº†FreeUæœºåˆ¶ï¼Œåˆ™ç¦ç”¨å®ƒã€‚

**ç¤ºä¾‹**:
```python
# ç¦ç”¨FreeU
pipeline.disable_freeu()
```

---

### 31. `fuse_qkv_projections` æ–¹æ³•
```python
def fuse_qkv_projections(self, unet: bool = True, vae: bool = True)
```
**æè¿°**: å¯ç”¨èåˆQKVæŠ•å½±ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œæ‰€æœ‰æŠ•å½±çŸ©é˜µï¼ˆæŸ¥è¯¢ã€é”®ã€å€¼ï¼‰éƒ½è¢«èåˆã€‚å¯¹äºäº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œé”®å’Œå€¼æŠ•å½±çŸ©é˜µè¢«èåˆã€‚

**å‚æ•°**:
- `unet` (`bool`, é»˜è®¤ `True`): æ˜¯å¦åœ¨UNetä¸Šåº”ç”¨èåˆ
- `vae` (`bool`, é»˜è®¤ `True`): æ˜¯å¦åœ¨VAEä¸Šåº”ç”¨èåˆ

**æ³¨æ„**: ğŸ§ª è¿™æ˜¯å®éªŒæ€§API

**é™åˆ¶**: VAEèåˆä»…æ”¯æŒ`AutoencoderKL`ç±»å‹

**ç¤ºä¾‹**:
```python
# èåˆUNetå’ŒVAEçš„QKVæŠ•å½±
pipeline.fuse_qkv_projections()

# ä»…èåˆUNet
pipeline.fuse_qkv_projections(unet=True, vae=False)
```

---

### 32. `unfuse_qkv_projections` æ–¹æ³•
```python
def unfuse_qkv_projections(self, unet: bool = True, vae: bool = True)
```
**æè¿°**: å¦‚æœå¯ç”¨äº†QKVæŠ•å½±èåˆï¼Œåˆ™ç¦ç”¨å®ƒã€‚

**å‚æ•°**:
- `unet` (`bool`, é»˜è®¤ `True`): æ˜¯å¦åœ¨UNetä¸Šå–æ¶ˆèåˆ
- `vae` (`bool`, é»˜è®¤ `True`): æ˜¯å¦åœ¨VAEä¸Šå–æ¶ˆèåˆ

**æ³¨æ„**: ğŸ§ª è¿™æ˜¯å®éªŒæ€§API

**ç¤ºä¾‹**:
```python
# å–æ¶ˆèåˆQKVæŠ•å½±
pipeline.unfuse_qkv_projections()
```

## å†…å­˜ä¼˜åŒ–ç­–ç•¥å¯¹æ¯”

| æ–¹æ³• | å†…å­˜èŠ‚çœ | æ€§èƒ½å½±å“ | é€‚ç”¨åœºæ™¯ |
|------|----------|----------|----------|
| `enable_model_cpu_offload()` | ä¸­ç­‰ | è½»å¾® | å¹³è¡¡å†…å­˜å’Œæ€§èƒ½ |
| `enable_sequential_cpu_offload()` | é«˜ | ä¸­ç­‰ | å†…å­˜æåº¦å—é™ |
| `enable_attention_slicing()` | ä¸­ç­‰ | è½»å¾® | å¤§æ‰¹æ¬¡æ¨ç† |
| `enable_vae_slicing()` | ä½ | å¾ˆè½»å¾® | VAEå†…å­˜ä¼˜åŒ– |
| `enable_vae_tiling()` | é«˜ | è½»å¾® | è¶…é«˜åˆ†è¾¨ç‡å›¾åƒ |
| `enable_xformers_memory_efficient_attention()` | ä¸­ç­‰ | è´Ÿå½±å“(åŠ é€Ÿ) | æœ‰xFormersç¯å¢ƒ |

## æœ€ä½³å®è·µ

### å†…å­˜å—é™ç¯å¢ƒ
```python
# æœ€å¤§å†…å­˜èŠ‚çœé…ç½®
pipeline.enable_sequential_cpu_offload()
pipeline.enable_attention_slicing("max")
pipeline.enable_vae_slicing()
pipeline.enable_vae_tiling()
```

### æ€§èƒ½ä¼˜å…ˆç¯å¢ƒ
```python
# æ€§èƒ½ä¼˜åŒ–é…ç½®
pipeline.to("cuda", torch.float16)
pipeline.enable_xformers_memory_efficient_attention()
pipeline.enable_model_cpu_offload()  # è½»å¾®å†…å­˜èŠ‚çœ
```

### é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆ
```python
# é«˜åˆ†è¾¨ç‡ä¼˜åŒ–
pipeline.enable_vae_tiling()
pipeline.enable_attention_slicing("auto")
pipeline.enable_model_cpu_offload()
```

