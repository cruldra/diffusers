<!DOCTYPE html>
<html>
<head>
<title>QwenImageEditPipeline__call__方法详解.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="qwenimageeditpipeline-call-%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3">QwenImageEditPipeline <code>__call__</code> 方法详解</h1>
<h2 id="%E6%A6%82%E8%BF%B0">概述</h2>
<p><code>QwenImageEditPipeline</code> 是基于 Qwen 多模态大模型的图像编辑管道，其 <code>__call__</code> 方法是执行图像编辑的核心接口。该方法接受原始图像和编辑指令，通过扩散模型生成编辑后的图像。</p>
<h2 id="%E6%96%B9%E6%B3%95%E7%AD%BE%E5%90%8D">方法签名</h2>
<pre class="hljs"><code><div><span class="hljs-meta">@torch.no_grad()</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__call__</span><span class="hljs-params">(
    self,
    image: Optional[PipelineImageInput] = None,
    prompt: Union[str, List[str]] = None,
    negative_prompt: Union[str, List[str]] = None,
    true_cfg_scale: float = <span class="hljs-number">4.0</span>,
    height: Optional[int] = None,
    width: Optional[int] = None,
    num_inference_steps: int = <span class="hljs-number">50</span>,
    sigmas: Optional[List[float]] = None,
    guidance_scale: float = <span class="hljs-number">1.0</span>,
    num_images_per_prompt: int = <span class="hljs-number">1</span>,
    generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,
    latents: Optional[torch.Tensor] = None,
    prompt_embeds: Optional[torch.Tensor] = None,
    prompt_embeds_mask: Optional[torch.Tensor] = None,
    negative_prompt_embeds: Optional[torch.Tensor] = None,
    negative_prompt_embeds_mask: Optional[torch.Tensor] = None,
    output_type: Optional[str] = <span class="hljs-string">"pil"</span>,
    return_dict: bool = True,
    attention_kwargs: Optional[Dict[str, Any]] = None,
    callback_on_step_end: Optional[Callable[[int, int, Dict], None]] = None,
    callback_on_step_end_tensor_inputs: List[str] = [<span class="hljs-string">"latents"</span>],
    max_sequence_length: int = <span class="hljs-number">512</span>,
)</span> -&gt; Union[QwenImagePipelineOutput, Tuple]:</span>
</div></code></pre>
<h2 id="%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3">参数详解</h2>
<h3 id="%E5%BF%85%E9%9C%80%E5%8F%82%E6%95%B0">必需参数</h3>
<ul>
<li><strong><code>image</code></strong> (<code>PipelineImageInput</code>): 待编辑的原始图像，支持 PIL.Image、numpy 数组或 torch.Tensor</li>
<li><strong><code>prompt</code></strong> (<code>str</code> 或 <code>List[str]</code>): 图像编辑指令，描述如何修改图像</li>
</ul>
<h3 id="%E6%8E%A7%E5%88%B6%E5%8F%82%E6%95%B0">控制参数</h3>
<ul>
<li><strong><code>negative_prompt</code></strong> (<code>str</code> 或 <code>List[str]</code>, 可选): 负面提示，描述不希望出现的内容</li>
<li><strong><code>true_cfg_scale</code></strong> (<code>float</code>, 默认 4.0): 真实 CFG 缩放因子，控制编辑强度</li>
<li><strong><code>guidance_scale</code></strong> (<code>float</code>, 默认 1.0): 引导缩放因子</li>
<li><strong><code>num_inference_steps</code></strong> (<code>int</code>, 默认 50): 推理步数，影响生成质量和速度</li>
</ul>
<h3 id="%E5%B0%BA%E5%AF%B8%E5%8F%82%E6%95%B0">尺寸参数</h3>
<ul>
<li><strong><code>height</code></strong> (<code>int</code>, 可选): 输出图像高度，默认根据输入图像计算</li>
<li><strong><code>width</code></strong> (<code>int</code>, 可选): 输出图像宽度，默认根据输入图像计算</li>
</ul>
<h3 id="%E7%94%9F%E6%88%90%E6%8E%A7%E5%88%B6">生成控制</h3>
<ul>
<li><strong><code>num_images_per_prompt</code></strong> (<code>int</code>, 默认 1): 每个提示生成的图像数量</li>
<li><strong><code>generator</code></strong> (<code>torch.Generator</code>, 可选): 随机数生成器，用于可重现的结果</li>
<li><strong><code>sigmas</code></strong> (<code>List[float]</code>, 可选): 自定义噪声调度参数</li>
</ul>
<h3 id="%E9%AB%98%E7%BA%A7%E5%8F%82%E6%95%B0">高级参数</h3>
<ul>
<li><strong><code>latents</code></strong> (<code>torch.Tensor</code>, 可选): 预计算的潜在表示</li>
<li><strong><code>prompt_embeds</code></strong> (<code>torch.Tensor</code>, 可选): 预计算的提示嵌入</li>
<li><strong><code>prompt_embeds_mask</code></strong> (<code>torch.Tensor</code>, 可选): 提示嵌入的掩码</li>
<li><strong><code>negative_prompt_embeds</code></strong> (<code>torch.Tensor</code>, 可选): 负面提示嵌入</li>
<li><strong><code>negative_prompt_embeds_mask</code></strong> (<code>torch.Tensor</code>, 可选): 负面提示嵌入掩码</li>
</ul>
<h3 id="%E8%BE%93%E5%87%BA%E6%8E%A7%E5%88%B6">输出控制</h3>
<ul>
<li><strong><code>output_type</code></strong> (<code>str</code>, 默认 &quot;pil&quot;): 输出格式，可选 &quot;pil&quot;、&quot;np&quot;、&quot;pt&quot; 或 &quot;latent&quot;</li>
<li><strong><code>return_dict</code></strong> (<code>bool</code>, 默认 True): 是否返回字典格式结果</li>
</ul>
<h3 id="%E5%9B%9E%E8%B0%83%E5%92%8C%E8%B0%83%E8%AF%95">回调和调试</h3>
<ul>
<li><strong><code>callback_on_step_end</code></strong> (<code>Callable</code>, 可选): 每步结束时的回调函数</li>
<li><strong><code>callback_on_step_end_tensor_inputs</code></strong> (<code>List[str]</code>): 传递给回调函数的张量名称</li>
<li><strong><code>attention_kwargs</code></strong> (<code>Dict</code>, 可选): 注意力机制的额外参数</li>
<li><strong><code>max_sequence_length</code></strong> (<code>int</code>, 默认 512): 最大序列长度</li>
</ul>
<h2 id="%E8%BF%94%E5%9B%9E%E5%80%BC">返回值</h2>
<h3 id="qwenimagepipelineoutput">QwenImagePipelineOutput</h3>
<p>当 <code>return_dict=True</code> 时返回 <code>QwenImagePipelineOutput</code> 对象：</p>
<pre class="hljs"><code><div><span class="hljs-meta">@dataclass</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QwenImagePipelineOutput</span><span class="hljs-params">(BaseOutput)</span>:</span>
    images: Union[List[PIL.Image.Image], np.ndarray]
</div></code></pre>
<ul>
<li><strong><code>images</code></strong>: 编辑后的图像列表（PIL.Image 格式）或 numpy 数组</li>
</ul>
<h3 id="tuple">Tuple</h3>
<p>当 <code>return_dict=False</code> 时返回元组：</p>
<pre class="hljs"><code><div>(images,)  <span class="hljs-comment"># 第一个元素是图像列表</span>
</div></code></pre>
<h2 id="%E5%86%85%E9%83%A8%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B">内部处理流程</h2>
<pre><code class="language-mermaid"><div class="mermaid">flowchart TD
    A[开始: __call__ 方法调用] --> B[1. 输入预处理]
    B --> B1[计算图像尺寸]
    B1 --> B2[调整为VAE倍数]
    B2 --> B3[验证输入参数]
    
    B3 --> C[2. 图像和文本编码]
    C --> C1[预处理输入图像]
    C1 --> C2[使用Qwen2.5-VL编码]
    C2 --> C3[生成提示嵌入]
    C3 --> C4{是否有负面提示?}
    C4 -->|是| C5[编码负面提示]
    C4 -->|否| D[3. 潜在空间准备]
    C5 --> D
    
    D --> D1[图像编码到潜在空间]
    D1 --> D2[初始化噪声潜在表示]
    D2 --> D3[准备图像形状信息]
    
    D3 --> E[4. 时间步调度]
    E --> E1[计算噪声调度参数]
    E1 --> E2[生成时间步序列]
    E2 --> E3[计算动态偏移参数]
    
    E3 --> F[5. 去噪循环开始]
    F --> F1{遍历时间步}
    F1 --> F2[准备模型输入]
    F2 --> F3[Transformer预测噪声]
    F3 --> F4{是否使用CFG?}
    F4 -->|是| F5[计算负面噪声预测]
    F4 -->|否| F6[应用调度器更新]
    F5 --> F7[应用CFG组合]
    F7 --> F6
    F6 --> F8[更新潜在表示]
    F8 --> F9{是否有回调?}
    F9 -->|是| F10[执行回调函数]
    F9 -->|否| F11{是否完成所有步骤?}
    F10 --> F11
    F11 -->|否| F1
    F11 -->|是| G[6. 后处理和输出]
    
    G --> G1{输出类型检查}
    G1 -->|latent| G2[直接返回潜在表示]
    G1 -->|其他| G3[VAE解码潜在表示]
    G3 --> G4[图像后处理]
    G4 --> G5[格式转换]
    G2 --> H[7. 返回结果]
    G5 --> H
    
    H --> H1{return_dict?}
    H1 -->|True| H2[返回QwenImagePipelineOutput]
    H1 -->|False| H3[返回元组]
    H2 --> I[结束]
    H3 --> I
    
    style A fill:#e1f5fe
    style I fill:#c8e6c9
    style F fill:#fff3e0
    style G fill:#f3e5f5
</div></code></pre>
<h2 id="%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B">使用示例</h2>
<h3 id="%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95">基本用法</h3>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> QwenImageEditPipeline
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image

<span class="hljs-comment"># 加载管道</span>
pipeline = QwenImageEditPipeline.from_pretrained(
    <span class="hljs-string">"Qwen/Qwen-Image-Edit"</span>, 
    torch_dtype=torch.bfloat16
)
pipeline.to(<span class="hljs-string">"cuda"</span>)

<span class="hljs-comment"># 加载图像</span>
image = Image.open(<span class="hljs-string">"input.jpg"</span>)

<span class="hljs-comment"># 执行编辑</span>
result = pipeline(
    image=image,
    prompt=<span class="hljs-string">"将猫咪的颜色改为金色"</span>,
    negative_prompt=<span class="hljs-string">"模糊，低质量"</span>,
    num_inference_steps=<span class="hljs-number">50</span>,
    true_cfg_scale=<span class="hljs-number">4.0</span>
)

<span class="hljs-comment"># 保存结果</span>
edited_image = result.images[<span class="hljs-number">0</span>]
edited_image.save(<span class="hljs-string">"edited_output.jpg"</span>)
</div></code></pre>
<h3 id="%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95">高级用法</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># 使用自定义参数</span>
result = pipeline(
    image=image,
    prompt=<span class="hljs-string">"添加彩虹背景"</span>,
    negative_prompt=<span class="hljs-string">"单调，无聊"</span>,
    height=<span class="hljs-number">1024</span>,
    width=<span class="hljs-number">1024</span>,
    num_inference_steps=<span class="hljs-number">100</span>,
    true_cfg_scale=<span class="hljs-number">6.0</span>,
    guidance_scale=<span class="hljs-number">1.5</span>,
    generator=torch.manual_seed(<span class="hljs-number">42</span>),  <span class="hljs-comment"># 可重现结果</span>
    num_images_per_prompt=<span class="hljs-number">4</span>,  <span class="hljs-comment"># 生成4张变体</span>
)

<span class="hljs-comment"># 获取所有生成的图像</span>
<span class="hljs-keyword">for</span> i, img <span class="hljs-keyword">in</span> enumerate(result.images):
    img.save(<span class="hljs-string">f"variant_<span class="hljs-subst">{i}</span>.jpg"</span>)
</div></code></pre>
<h2 id="%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82">技术细节</h2>
<h3 id="cfg-classifier-free-guidance-%E6%9C%BA%E5%88%B6">CFG (Classifier-Free Guidance) 机制</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># 当 true_cfg_scale &gt; 1 且有负面提示时启用</span>
<span class="hljs-keyword">if</span> do_true_cfg:
    <span class="hljs-comment"># 计算条件和无条件噪声预测</span>
    comb_pred = neg_noise_pred + true_cfg_scale * (noise_pred - neg_noise_pred)

    <span class="hljs-comment"># 归一化处理，保持噪声强度</span>
    cond_norm = torch.norm(noise_pred, dim=<span class="hljs-number">-1</span>, keepdim=<span class="hljs-literal">True</span>)
    noise_norm = torch.norm(comb_pred, dim=<span class="hljs-number">-1</span>, keepdim=<span class="hljs-literal">True</span>)
    noise_pred = comb_pred * (cond_norm / noise_norm)
</div></code></pre>
<h3 id="%E6%8F%90%E7%A4%BA%E6%A8%A1%E6%9D%BF">提示模板</h3>
<p>QwenImageEditPipeline 使用特定的提示模板来指导编辑：</p>
<pre class="hljs"><code><div>template = <span class="hljs-string">"&lt;|im_start|&gt;system\nDescribe the key features of the input image (color, shape, size, texture, objects, background), then explain how the user's text instruction should alter or modify the image. Generate a new image that meets the user's requirements while maintaining consistency with the original input where appropriate.&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\n&lt;|vision_start|&gt;&lt;|image_pad|&gt;&lt;|vision_end|&gt;{}&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n"</span>
</div></code></pre>
<h3 id="%E6%BD%9C%E5%9C%A8%E7%A9%BA%E9%97%B4%E5%A4%84%E7%90%86">潜在空间处理</h3>
<ul>
<li><strong>编码</strong>: 图像通过 VAE 编码器转换为潜在表示</li>
<li><strong>缩放因子</strong>: 使用 <code>vae_scale_factor * 2</code> 进行尺寸调整</li>
<li><strong>打包</strong>: 潜在表示被打包成 2x2 补丁格式</li>
</ul>
<h3 id="%E6%97%B6%E9%97%B4%E6%AD%A5%E8%B0%83%E5%BA%A6">时间步调度</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># 动态偏移计算</span>
mu = calculate_shift(
    image_seq_len,
    base_image_seq_len=<span class="hljs-number">256</span>,
    max_image_seq_len=<span class="hljs-number">4096</span>,
    base_shift=<span class="hljs-number">0.5</span>,
    max_shift=<span class="hljs-number">1.15</span>
)

<span class="hljs-comment"># 时间步生成</span>
timesteps, num_inference_steps = retrieve_timesteps(
    scheduler, num_inference_steps, device, sigmas=sigmas, mu=mu
)
</div></code></pre>
<h2 id="%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%AE">性能优化建议</h2>
<ol>
<li><strong>推理步数</strong>: 50步通常足够，更多步数提升有限</li>
<li><strong>CFG缩放</strong>: 4.0-6.0 范围内效果较好</li>
<li><strong>批处理</strong>: 使用 <code>num_images_per_prompt</code> 批量生成</li>
<li><strong>内存管理</strong>: 使用 <code>enable_model_cpu_offload()</code> 节省显存</li>
<li><strong>精度</strong>: 使用 <code>torch.bfloat16</code> 平衡速度和质量</li>
</ol>
<h2 id="%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">常见问题和解决方案</h2>
<h3 id="1-%E5%86%85%E5%AD%98%E4%B8%8D%E8%B6%B3">1. 内存不足</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># 启用CPU卸载</span>
pipeline.enable_model_cpu_offload()

<span class="hljs-comment"># 或启用顺序CPU卸载</span>
pipeline.enable_sequential_cpu_offload()
</div></code></pre>
<h3 id="2-%E7%94%9F%E6%88%90%E8%B4%A8%E9%87%8F%E4%B8%8D%E4%BD%B3">2. 生成质量不佳</h3>
<ul>
<li>增加推理步数到 75-100</li>
<li>调整 <code>true_cfg_scale</code> 到 5.0-7.0</li>
<li>优化提示词描述</li>
</ul>
<h3 id="3-%E7%BC%96%E8%BE%91%E6%95%88%E6%9E%9C%E4%B8%8D%E6%98%8E%E6%98%BE">3. 编辑效果不明显</h3>
<ul>
<li>提高 <code>true_cfg_scale</code> 值</li>
<li>使用更具体的编辑指令</li>
<li>确保负面提示合适</li>
</ul>
<h3 id="4-%E9%80%9F%E5%BA%A6%E4%BC%98%E5%8C%96">4. 速度优化</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># 使用编译优化（PyTorch 2.0+）</span>
pipeline.transformer = torch.compile(pipeline.transformer)

<span class="hljs-comment"># 减少推理步数</span>
result = pipeline(..., num_inference_steps=<span class="hljs-number">25</span>)
</div></code></pre>
<h2 id="%E4%B8%8E%E5%85%B6%E4%BB%96pipeline%E7%9A%84%E5%8C%BA%E5%88%AB">与其他Pipeline的区别</h2>
<table>
<thead>
<tr>
<th>特性</th>
<th>QwenImageEditPipeline</th>
<th>StableDiffusionImg2ImgPipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td>文本编码器</td>
<td>Qwen2.5-VL (多模态)</td>
<td>CLIP (纯文本)</td>
</tr>
<tr>
<td>图像理解</td>
<td>原生支持</td>
<td>需要额外处理</td>
</tr>
<tr>
<td>编辑精度</td>
<td>高（理解图像内容）</td>
<td>中等</td>
</tr>
<tr>
<td>提示模板</td>
<td>专用编辑模板</td>
<td>通用模板</td>
</tr>
<tr>
<td>CFG机制</td>
<td>True CFG</td>
<td>标准CFG</td>
</tr>
</tbody>
</table>

</body>
</html>
