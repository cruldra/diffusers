<!DOCTYPE html>
<html>
<head>
<title>QwenImageControlNetPipeline__call__方法详解.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="qwenimagecontrolnetpipeline-call-%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3">QwenImageControlNetPipeline <code>__call__</code> 方法详解</h1>
<h2 id="%E6%A6%82%E8%BF%B0">概述</h2>
<p><code>QwenImageControlNetPipeline</code> 是基于 Qwen 多模态大模型的 ControlNet 图像生成管道，其 <code>__call__</code> 方法是执行条件图像生成的核心接口。该方法接受文本提示和控制图像，通过 ControlNet 引导扩散模型生成符合特定结构或边缘的图像。</p>
<h2 id="%E6%96%B9%E6%B3%95%E7%AD%BE%E5%90%8D">方法签名</h2>
<pre class="hljs"><code><div><span class="hljs-meta">@torch.no_grad()</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__call__</span><span class="hljs-params">(
    self,
    prompt: Union[str, List[str]] = None,
    negative_prompt: Union[str, List[str]] = None,
    true_cfg_scale: float = <span class="hljs-number">4.0</span>,
    height: Optional[int] = None,
    width: Optional[int] = None,
    num_inference_steps: int = <span class="hljs-number">50</span>,
    sigmas: Optional[List[float]] = None,
    guidance_scale: float = <span class="hljs-number">1.0</span>,
    control_guidance_start: Union[float, List[float]] = <span class="hljs-number">0.0</span>,
    control_guidance_end: Union[float, List[float]] = <span class="hljs-number">1.0</span>,
    control_image: PipelineImageInput = None,
    controlnet_conditioning_scale: Union[float, List[float]] = <span class="hljs-number">1.0</span>,
    num_images_per_prompt: int = <span class="hljs-number">1</span>,
    generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,
    latents: Optional[torch.Tensor] = None,
    prompt_embeds: Optional[torch.Tensor] = None,
    prompt_embeds_mask: Optional[torch.Tensor] = None,
    negative_prompt_embeds: Optional[torch.Tensor] = None,
    negative_prompt_embeds_mask: Optional[torch.Tensor] = None,
    output_type: Optional[str] = <span class="hljs-string">"pil"</span>,
    return_dict: bool = True,
    attention_kwargs: Optional[Dict[str, Any]] = None,
    callback_on_step_end: Optional[Callable[[int, int, Dict], None]] = None,
    callback_on_step_end_tensor_inputs: List[str] = [<span class="hljs-string">"latents"</span>],
    max_sequence_length: int = <span class="hljs-number">512</span>,
)</span> -&gt; Union[QwenImagePipelineOutput, Tuple]:</span>
</div></code></pre>
<h2 id="%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3">参数详解</h2>
<h3 id="%E5%BF%85%E9%9C%80%E5%8F%82%E6%95%B0">必需参数</h3>
<ul>
<li><strong><code>prompt</code></strong> (<code>str</code> 或 <code>List[str]</code>): 文本提示，描述要生成的图像内容</li>
<li><strong><code>control_image</code></strong> (<code>PipelineImageInput</code>): 控制图像，提供结构或边缘信息</li>
</ul>
<h3 id="controlnet-%E7%89%B9%E6%9C%89%E5%8F%82%E6%95%B0">ControlNet 特有参数</h3>
<ul>
<li><strong><code>control_guidance_start</code></strong> (<code>float</code> 或 <code>List[float]</code>, 默认 0.0): ControlNet 引导开始时间点</li>
<li><strong><code>control_guidance_end</code></strong> (<code>float</code> 或 <code>List[float]</code>, 默认 1.0): ControlNet 引导结束时间点</li>
<li><strong><code>controlnet_conditioning_scale</code></strong> (<code>float</code> 或 <code>List[float]</code>, 默认 1.0): ControlNet 条件缩放因子</li>
</ul>
<h3 id="%E6%8E%A7%E5%88%B6%E5%8F%82%E6%95%B0">控制参数</h3>
<ul>
<li><strong><code>negative_prompt</code></strong> (<code>str</code> 或 <code>List[str]</code>, 可选): 负面提示</li>
<li><strong><code>true_cfg_scale</code></strong> (<code>float</code>, 默认 4.0): 真实 CFG 缩放因子</li>
<li><strong><code>guidance_scale</code></strong> (<code>float</code>, 默认 1.0): 引导缩放因子</li>
<li><strong><code>num_inference_steps</code></strong> (<code>int</code>, 默认 50): 推理步数</li>
</ul>
<h3 id="%E5%B0%BA%E5%AF%B8%E5%8F%82%E6%95%B0">尺寸参数</h3>
<ul>
<li><strong><code>height</code></strong> (<code>int</code>, 可选): 输出图像高度</li>
<li><strong><code>width</code></strong> (<code>int</code>, 可选): 输出图像宽度</li>
</ul>
<h3 id="%E7%94%9F%E6%88%90%E6%8E%A7%E5%88%B6">生成控制</h3>
<ul>
<li><strong><code>num_images_per_prompt</code></strong> (<code>int</code>, 默认 1): 每个提示生成的图像数量</li>
<li><strong><code>generator</code></strong> (<code>torch.Generator</code>, 可选): 随机数生成器</li>
<li><strong><code>sigmas</code></strong> (<code>List[float]</code>, 可选): 自定义噪声调度参数</li>
</ul>
<h3 id="%E9%AB%98%E7%BA%A7%E5%8F%82%E6%95%B0">高级参数</h3>
<ul>
<li><strong><code>latents</code></strong> (<code>torch.Tensor</code>, 可选): 预计算的潜在表示</li>
<li><strong><code>prompt_embeds</code></strong> (<code>torch.Tensor</code>, 可选): 预计算的提示嵌入</li>
<li><strong><code>prompt_embeds_mask</code></strong> (<code>torch.Tensor</code>, 可选): 提示嵌入的掩码</li>
<li><strong><code>negative_prompt_embeds</code></strong> (<code>torch.Tensor</code>, 可选): 负面提示嵌入</li>
<li><strong><code>negative_prompt_embeds_mask</code></strong> (<code>torch.Tensor</code>, 可选): 负面提示嵌入掩码</li>
</ul>
<h3 id="%E8%BE%93%E5%87%BA%E6%8E%A7%E5%88%B6">输出控制</h3>
<ul>
<li><strong><code>output_type</code></strong> (<code>str</code>, 默认 &quot;pil&quot;): 输出格式</li>
<li><strong><code>return_dict</code></strong> (<code>bool</code>, 默认 True): 是否返回字典格式结果</li>
</ul>
<h3 id="%E5%9B%9E%E8%B0%83%E5%92%8C%E8%B0%83%E8%AF%95">回调和调试</h3>
<ul>
<li><strong><code>callback_on_step_end</code></strong> (<code>Callable</code>, 可选): 每步结束时的回调函数</li>
<li><strong><code>callback_on_step_end_tensor_inputs</code></strong> (<code>List[str]</code>): 传递给回调函数的张量名称</li>
<li><strong><code>attention_kwargs</code></strong> (<code>Dict</code>, 可选): 注意力机制的额外参数</li>
<li><strong><code>max_sequence_length</code></strong> (<code>int</code>, 默认 512): 最大序列长度</li>
</ul>
<h2 id="%E8%BF%94%E5%9B%9E%E5%80%BC">返回值</h2>
<h3 id="qwenimagepipelineoutput">QwenImagePipelineOutput</h3>
<p>当 <code>return_dict=True</code> 时返回 <code>QwenImagePipelineOutput</code> 对象：</p>
<pre class="hljs"><code><div><span class="hljs-meta">@dataclass</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QwenImagePipelineOutput</span><span class="hljs-params">(BaseOutput)</span>:</span>
    images: Union[List[PIL.Image.Image], np.ndarray]
</div></code></pre>
<h3 id="tuple">Tuple</h3>
<p>当 <code>return_dict=False</code> 时返回元组：</p>
<pre class="hljs"><code><div>(images,)  <span class="hljs-comment"># 第一个元素是图像列表</span>
</div></code></pre>
<h2 id="%E5%86%85%E9%83%A8%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B">内部处理流程</h2>
<pre><code class="language-mermaid"><div class="mermaid">flowchart TD
    A[开始: __call__ 方法调用] --> B[1. 输入预处理]
    B --> B1[验证输入参数]
    B1 --> B2[计算图像尺寸]
    B2 --> B3[设置批次大小]
    
    B3 --> C[2. 文本编码]
    C --> C1[编码正面提示]
    C1 --> C2{是否有负面提示?}
    C2 -->|是| C3[编码负面提示]
    C2 -->|否| D[3. 控制图像处理]
    C3 --> D
    
    D --> D1[预处理控制图像]
    D1 --> D2[VAE编码控制图像]
    D2 --> D3[打包控制潜在表示]
    D3 --> D4{单个还是多个ControlNet?}
    D4 -->|单个| D5[处理单个控制图像]
    D4 -->|多个| D6[处理多个控制图像]
    D5 --> E[4. 潜在空间准备]
    D6 --> E
    
    E --> E1[初始化噪声潜在表示]
    E1 --> E2[准备图像形状信息]
    E2 --> E3[计算控制引导时间范围]
    
    E3 --> F[5. 时间步调度]
    F --> F1[计算噪声调度参数]
    F1 --> F2[生成时间步序列]
    F2 --> F3[计算动态偏移参数]
    
    F3 --> G[6. 去噪循环开始]
    G --> G1{遍历时间步}
    G1 --> G2[计算当前控制缩放]
    G2 --> G3[ControlNet前向传播]
    G3 --> G4[获取控制块样本]
    G4 --> G5[Transformer预测噪声]
    G5 --> G6{是否使用CFG?}
    G6 -->|是| G7[计算负面噪声预测]
    G6 -->|否| G8[应用调度器更新]
    G7 --> G9[应用CFG组合]
    G9 --> G8
    G8 --> G10[更新潜在表示]
    G10 --> G11{是否有回调?}
    G11 -->|是| G12[执行回调函数]
    G11 -->|否| G13{是否完成所有步骤?}
    G12 --> G13
    G13 -->|否| G1
    G13 -->|是| H[7. 后处理和输出]
    
    H --> H1{输出类型检查}
    H1 -->|latent| H2[直接返回潜在表示]
    H1 -->|其他| H3[VAE解码潜在表示]
    H3 --> H4[图像后处理]
    H4 --> H5[格式转换]
    H2 --> I[8. 返回结果]
    H5 --> I
    
    I --> I1{return_dict?}
    I1 -->|True| I2[返回QwenImagePipelineOutput]
    I1 -->|False| I3[返回元组]
    I2 --> J[结束]
    I3 --> J
    
    style A fill:#e1f5fe
    style J fill:#c8e6c9
    style G fill:#fff3e0
    style H fill:#f3e5f5
    style D fill:#e8f5e8
</div></code></pre>
<h2 id="%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82">技术细节</h2>
<h3 id="controlnet-%E6%9C%BA%E5%88%B6">ControlNet 机制</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># ControlNet 前向传播</span>
controlnet_block_samples = self.controlnet(
    hidden_states=latents,
    controlnet_cond=control_image,
    conditioning_scale=cond_scale,
    timestep=timestep / <span class="hljs-number">1000</span>,
    encoder_hidden_states=prompt_embeds,
    encoder_hidden_states_mask=prompt_embeds_mask,
    img_shapes=img_shapes,
    txt_seq_lens=prompt_embeds_mask.sum(dim=<span class="hljs-number">1</span>).tolist(),
    return_dict=<span class="hljs-literal">False</span>,
)

<span class="hljs-comment"># 将控制块样本传递给 Transformer</span>
noise_pred = self.transformer(
    hidden_states=latents,
    timestep=timestep / <span class="hljs-number">1000</span>,
    encoder_hidden_states=prompt_embeds,
    encoder_hidden_states_mask=prompt_embeds_mask,
    img_shapes=img_shapes,
    txt_seq_lens=prompt_embeds_mask.sum(dim=<span class="hljs-number">1</span>).tolist(),
    controlnet_block_samples=controlnet_block_samples,  <span class="hljs-comment"># 关键：控制信息</span>
    attention_kwargs=self.attention_kwargs,
    return_dict=<span class="hljs-literal">False</span>,
)[<span class="hljs-number">0</span>]
</div></code></pre>
<h3 id="%E6%8E%A7%E5%88%B6%E5%BC%95%E5%AF%BC%E6%97%B6%E9%97%B4%E8%B0%83%E5%BA%A6">控制引导时间调度</h3>
<pre class="hljs"><code><div><span class="hljs-comment"># 计算每个时间步的控制缩放</span>
<span class="hljs-keyword">if</span> isinstance(controlnet_keep[i], list):
    cond_scale = [c * s <span class="hljs-keyword">for</span> c, s <span class="hljs-keyword">in</span> zip(controlnet_conditioning_scale, controlnet_keep[i])]
<span class="hljs-keyword">else</span>:
    controlnet_cond_scale = controlnet_conditioning_scale
    <span class="hljs-keyword">if</span> isinstance(controlnet_cond_scale, list):
        controlnet_cond_scale = controlnet_cond_scale[<span class="hljs-number">0</span>]
    cond_scale = controlnet_cond_scale * controlnet_keep[i]
</div></code></pre>
<h3 id="%E5%A4%9A-controlnet-%E6%94%AF%E6%8C%81">多 ControlNet 支持</h3>
<ul>
<li>支持 <code>QwenImageControlNetModel</code>（单个）</li>
<li>支持 <code>QwenImageMultiControlNetModel</code>（多个）</li>
<li>每个 ControlNet 可以有独立的缩放因子和引导时间范围</li>
</ul>
<h2 id="%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B">使用示例</h2>
<h3 id="%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%E5%8D%95%E4%B8%AA-controlnet">基本用法（单个 ControlNet）</h3>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> QwenImageControlNetPipeline
<span class="hljs-keyword">from</span> diffusers.models.controlnets <span class="hljs-keyword">import</span> QwenImageControlNetModel
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image

<span class="hljs-comment"># 加载 ControlNet 模型</span>
controlnet = QwenImageControlNetModel.from_pretrained(
    <span class="hljs-string">"InstantX/Qwen-Image-ControlNet-Union"</span>, 
    torch_dtype=torch.bfloat16
)

<span class="hljs-comment"># 加载管道</span>
pipeline = QwenImageControlNetPipeline.from_pretrained(
    <span class="hljs-string">"Qwen/Qwen-Image"</span>, 
    controlnet=controlnet,
    torch_dtype=torch.bfloat16
)
pipeline.to(<span class="hljs-string">"cuda"</span>)

<span class="hljs-comment"># 加载控制图像（如 Canny 边缘图）</span>
control_image = Image.open(<span class="hljs-string">"canny_edge.png"</span>)

<span class="hljs-comment"># 生成图像</span>
result = pipeline(
    prompt=<span class="hljs-string">"传统亚洲宝塔，精美的金色装饰，天蓝色和白色调色板"</span>,
    negative_prompt=<span class="hljs-string">"模糊，低质量"</span>,
    control_image=control_image,
    controlnet_conditioning_scale=<span class="hljs-number">1.0</span>,
    num_inference_steps=<span class="hljs-number">30</span>,
    true_cfg_scale=<span class="hljs-number">4.0</span>
)

<span class="hljs-comment"># 保存结果</span>
generated_image = result.images[<span class="hljs-number">0</span>]
generated_image.save(<span class="hljs-string">"controlnet_output.jpg"</span>)
</div></code></pre>
<h3 id="%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95%E5%A4%9A%E4%B8%AA-controlnet">高级用法（多个 ControlNet）</h3>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> diffusers.models.controlnets <span class="hljs-keyword">import</span> QwenImageMultiControlNetModel

<span class="hljs-comment"># 创建多个 ControlNet</span>
controlnet1 = QwenImageControlNetModel.from_pretrained(
    <span class="hljs-string">"InstantX/Qwen-Image-ControlNet-Union"</span>, torch_dtype=torch.bfloat16
)
controlnet2 = QwenImageControlNetModel.from_pretrained(
    <span class="hljs-string">"InstantX/Qwen-Image-ControlNet-Union"</span>, torch_dtype=torch.bfloat16
)

<span class="hljs-comment"># 组合多个 ControlNet</span>
multi_controlnet = QwenImageMultiControlNetModel([controlnet1, controlnet2])

<span class="hljs-comment"># 加载管道</span>
pipeline = QwenImageControlNetPipeline.from_pretrained(
    <span class="hljs-string">"Qwen/Qwen-Image"</span>, 
    controlnet=multi_controlnet,
    torch_dtype=torch.bfloat16
)
pipeline.to(<span class="hljs-string">"cuda"</span>)

<span class="hljs-comment"># 使用多个控制图像</span>
control_images = [canny_image, depth_image]

<span class="hljs-comment"># 生成图像</span>
result = pipeline(
    prompt=<span class="hljs-string">"现代建筑设计，玻璃幕墙，城市景观"</span>,
    negative_prompt=<span class="hljs-string">"模糊，扭曲"</span>,
    control_image=control_images,
    controlnet_conditioning_scale=[<span class="hljs-number">0.8</span>, <span class="hljs-number">0.6</span>],  <span class="hljs-comment"># 不同的缩放因子</span>
    control_guidance_start=[<span class="hljs-number">0.0</span>, <span class="hljs-number">0.1</span>],         <span class="hljs-comment"># 不同的开始时间</span>
    control_guidance_end=[<span class="hljs-number">0.9</span>, <span class="hljs-number">0.8</span>],           <span class="hljs-comment"># 不同的结束时间</span>
    num_inference_steps=<span class="hljs-number">50</span>,
    true_cfg_scale=<span class="hljs-number">5.0</span>
)
</div></code></pre>
<h2 id="%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%AE">性能优化建议</h2>
<ol>
<li><strong>控制强度</strong>: <code>controlnet_conditioning_scale</code> 在 0.5-1.5 范围内效果较好</li>
<li><strong>引导时间</strong>: 通常在去噪过程的前 80-90% 时间内使用控制引导</li>
<li><strong>推理步数</strong>: 30-50 步通常足够，ControlNet 收敛较快</li>
<li><strong>内存优化</strong>: 使用 <code>enable_model_cpu_offload()</code> 处理大型 ControlNet</li>
<li><strong>批处理</strong>: 多个控制图像可以批量处理提高效率</li>
</ol>
<h2 id="%E4%B8%8E%E5%85%B6%E4%BB%96-pipeline-%E7%9A%84%E5%8C%BA%E5%88%AB">与其他 Pipeline 的区别</h2>
<table>
<thead>
<tr>
<th>特性</th>
<th>QwenImageControlNetPipeline</th>
<th>StableDiffusionControlNetPipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td>文本编码器</td>
<td>Qwen2.5-VL (多模态)</td>
<td>CLIP (纯文本)</td>
</tr>
<tr>
<td>ControlNet 类型</td>
<td>QwenImageControlNet</td>
<td>ControlNet</td>
</tr>
<tr>
<td>多模态理解</td>
<td>原生支持</td>
<td>不支持</td>
</tr>
<tr>
<td>控制精度</td>
<td>高（理解图像语义）</td>
<td>中等</td>
</tr>
<tr>
<td>支持的控制类型</td>
<td>Union ControlNet</td>
<td>单一类型</td>
</tr>
</tbody>
</table>

</body>
</html>
